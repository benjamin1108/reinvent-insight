# ============================================================================
# 统一模型配置文件
# ============================================================================
# 
# 该配置文件定义了不同任务类型使用的AI模型及其参数。
# 
# 配置优先级：
#   1. 运行时参数（最高优先级）
#   2. 环境变量（格式：MODEL_{TASK_TYPE}_{PARAMETER}）
#   3. 本配置文件
#   4. 默认值（最低优先级）
#
# 环境变量示例：
#   MODEL_PDF_PROCESSING_MODEL_NAME=gemini-2.5-pro
#   MODEL_VIDEO_SUMMARY_TEMPERATURE=0.8
#
# ============================================================================

# ----------------------------------------------------------------------------
# 默认配置
# ----------------------------------------------------------------------------
# 当任务类型未定义特定配置时，使用此默认配置
default:
  # 模型提供商：gemini, xai, alibaba
  provider: gemini
  
  # 模型名称
  model_name: gemini-3-pro-preview
  
  # API Key 环境变量名称（实际的 API Key 从环境变量读取）
  api_key_env: GEMINI_API_KEY
  
  # 生成参数
  generation:
    # 温度：控制输出的随机性 (0.0-1.0)
    # 较低的值使输出更确定，较高的值使输出更有创造性
    temperature: 0.5
    
    # Top-p：核采样参数 (0.0-1.0)
    # 控制输出的多样性
    top_p: 0.9
    
    # Top-k：候选词数量
    # 限制每步采样的候选词数量
    top_k: 40
    
    # 最大输出令牌数
    max_output_tokens: 65535
  
  # 速率限制
  rate_limit:
    # API 调用间隔（秒）
    interval: 0.5
    
    # 最大重试次数
    max_retries: 3
    
    # 重试退避基数（指数退避）
    retry_backoff_base: 2.0

# ----------------------------------------------------------------------------
# 任务特定配置
# ----------------------------------------------------------------------------
tasks:
  # --------------------------------------------------------------------------
  # 视频摘要任务
  # --------------------------------------------------------------------------
  # 用于处理 YouTube 视频字幕，生成深度解读文章
  video_summary:
    provider: gemini
    model_name: gemini-3-pro-preview
    api_key_env: GEMINI_API_KEY
    
    # 思考模式配置
    thinking:
      # 是否启用低思考模式（low thinking）
      # false: 高思考模式（默认，深度分析）
      # true: 低思考模式（快速响应）
      low_thinking: false
    
    generation:
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      # 视频摘要需要更大的输出空间
      max_output_tokens: 65535
    
    rate_limit:
      interval: 0.5
      max_retries: 3
      retry_backoff_base: 2.0

  # --------------------------------------------------------------------------
  # PDF 处理任务
  # --------------------------------------------------------------------------
  # 用于处理 PDF 文档，进行多模态分析（文本+图表）
  pdf_processing:
    provider: gemini
    model_name: gemini-3-pro-preview
    api_key_env: GEMINI_API_KEY
    
    # 思考模式配置
    thinking:
      low_thinking: false  # 使用高思考模式
    
    generation:
      # PDF 分析使用稍高的温度以获得更有创造性的解读
      temperature: 0.5
      top_p: 0.9
      top_k: 40
      max_output_tokens: 8000
    
    rate_limit:
      interval: 0.5
      max_retries: 3
      retry_backoff_base: 2.0

  # --------------------------------------------------------------------------
  # 可视化生成任务
  # --------------------------------------------------------------------------
  # 用于将深度解读文章转换为可视化 HTML 网页
  visual_generation:
    provider: gemini
    model_name: gemini-3-pro-preview
    api_key_env: GEMINI_API_KEY
    
    # 思考模式配置
    thinking:
      low_thinking: false  # 使用高思考模式
    
    generation:
      # 可视化生成需要更高的创造性
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      # 生成 HTML 需要较大的输出空间
      max_output_tokens: 128000
    
    rate_limit:
      interval: 1  # 增加请求间隔
      max_retries: 5  # 增加重试次数
      retry_backoff_base: 2.5  # 增大退避基数

  # --------------------------------------------------------------------------
  # 文档分析任务
  # --------------------------------------------------------------------------
  # 用于处理 TXT、MD、DOCX 等文档格式
  document_analysis:
    provider: gemini
    model_name: gemini-3-pro-preview
    api_key_env: GEMINI_API_KEY
    
    # 思考模式配置
    thinking:
      low_thinking: false  # 使用高思考模式
    
    generation:
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      max_output_tokens: 128000
    
    rate_limit:
      interval: 0.5
      max_retries: 3
      retry_backoff_base: 2.0

  # --------------------------------------------------------------------------
  # HTML转Markdown任务
  # --------------------------------------------------------------------------
  # 用于将HTML网页转换为格式化的Markdown文档
  # 
  # 思考模式说明：
  # - low_thinking: true  适合格式转换、翻译等任务（快速响应）
  # - low_thinking: false 适合需要深度分析、创造性的任务（高质量输出）
  html_to_markdown:
    provider: gemini
    model_name: gemini-3-pro-preview
    api_key_env: GEMINI_API_KEY
    
    # 思考模式配置
    thinking:
      low_thinking: true  # 使用低思考模式（快速转换，不需要深度分析）
    
    generation:
      # 使用较低温度以获得稳定、准确的输出
      temperature: 0.3
      top_p: 0.9
      top_k: 40
      # 足够大以处理长文章
      max_output_tokens: 16000
    
    rate_limit:
      interval: 1.0  # 增加请求间隔，避免频繁调用
      max_retries: 5  # 增加重试次数
      retry_backoff_base: 2.5  # 增大退避基数
      timeout: 300  # API超时时间（秒），处理大HTML时需要更长时间
      concurrent_delay: 2  # 并发处理时每个任务的启动间隔（秒），用于分段处理

  # --------------------------------------------------------------------------
  # 文本转语音任务
  # --------------------------------------------------------------------------
  # 用于将文章内容转换为语音，使用阿里云qwen3-tts-flash-2025-11-27
  text_to_speech:
    # provider: dashscope
    # model_name: qwen3-tts-flash-2025-11-27
    # api_key_env: DASHSCOPE_API_KEY
    
    provider: gemini
    model_name: gemini-2.5-pro-preview-tts
    api_key_env: GEMINI_API_KEY
    generation:
      # TTS 不使用这些参数，但保留用于框架兼容性
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      max_output_tokens: 50000
    
    rate_limit:
      # Qwen TTS API 调用间隔（秒）
      interval: 1
      max_retries: 3
      retry_backoff_base: 2.0
    
    # TTS 特定配置
    tts:
      # 默认音色（Gemini TTS 支持的语音）
      # 常用选择：
      #   - kore: 女声，清晰自然
      #   - puck: 男声，温和有力
      #   - charon: 男声，成熟稳重
      #   - aoede: 女声，温柔甜美
      # 完整列表: achernar, achird, algenib, algieba, alnilam, aoede, autonoe, 
      #           callirrhoe, charon, despina, enceladus, erinome, fenrir, gacrux, 
      #           iapetus, kore, laomedeia, leda, orus, puck, pulcherrima, 
      #           rasalgethi, sadachbia, sadaltager, schedar, sulafat, umbriel, 
      #           vindemiatrix, zephyr, zubenelgenubi
      default_voice: autonoe
      
      # 默认语言
      # 支持: Chinese(中文), English(英文), Cantonese(粤语)
      default_language: Chinese
      
      # 采样率（Hz）- Qwen TTS 支持 8000, 16000, 24000, 48000
      sample_rate: 24000
      
      # 音频格式 - Qwen 返回 PCM，我们组装成 WAV
      audio_format: wav
      
      # 是否启用缓存
      cache_enabled: true
      
      # 缓存最大大小（MB）
      cache_max_size_mb: 500
      
      # 缓存目录
      cache_dir: downloads/tts_cache

# ============================================================================
# 配置说明
# ============================================================================
#
# 1. 模型选择建议：
#    - gemini-2.5-pro: 最强大的模型，适合复杂任务（视频摘要、可视化生成）
#    - gemini-2.0-flash-exp: 更快的响应速度，适合实时任务（PDF处理）
#
# 2. 温度参数调优：
#    - 0.0-0.3: 非常确定性，适合事实性任务
#    - 0.4-0.7: 平衡创造性和准确性，适合大多数任务
#    - 0.8-1.0: 高创造性，适合内容生成任务
#
# 3. 思考模式（thinking）配置：
#    - low_thinking: true  (低思考模式)
#      * 适用场景：格式转换、翻译、数据提取等结构化任务
#      * 优势：响应速度快，成本低
#      * 示例：HTML转Markdown、JSON解析、简单问答
#    
#    - low_thinking: false (高思考模式，默认)
#      * 适用场景：深度分析、创意生成、复杂推理任务
#      * 优势：输出质量高，理解更深入
#      * 示例：视频摘要、PDF分析、可视化生成、文档解读
#    
#    注意：如果任务类型未配置 thinking 字段，默认使用高思考模式
#
# 4. 速率限制：
#    - interval: 根据 API 配额调整，避免触发速率限制
#    - max_retries: 建议 3-5 次，平衡可靠性和响应时间
#
# 5. 环境变量覆盖示例：
#    export MODEL_PDF_PROCESSING_MODEL_NAME=gemini-2.5-pro
#    export MODEL_VIDEO_SUMMARY_TEMPERATURE=0.8
#    export MODEL_HTML_TO_MARKDOWN_LOW_THINKING=true
#    export MODEL_DEFAULT_API_KEY=your-api-key-here
#
# ============================================================================

  # --------------------------------------------------------------------------
  # DashScope 配置（阿里云通义千问）
  # --------------------------------------------------------------------------
  
  # 视频摘要任务 - 使用 DashScope
  # dashscope_video_summary:
  #   provider: dashscope
  #   model_name: qwen3-max  # 可选: qwen-turbo, qwen-plus, qwen-max, qwen-max-longcontext
  #   api_key_env: DASHSCOPE_API_KEY
    
  #   generation:
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 40  # DashScope 不使用 top_k，但保留用于兼容性
  #     max_output_tokens: 8000
    
  #   rate_limit:
  #     interval: 0.5
  #     max_retries: 3
  #     retry_backoff_base: 2.0

  # # PDF 处理任务 - 使用 DashScope 多模态
  # dashscope_pdf_processing:
  #   provider: dashscope
  #   model_name: qwen-vl-max  # 多模态模型: qwen-vl-plus, qwen-vl-max
  #   api_key_env: DASHSCOPE_API_KEY
    
  #   generation:
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 40
  #     max_output_tokens: 8000
    
  #   rate_limit:
  #     interval: 0.5
  #     max_retries: 3
  #     retry_backoff_base: 2.0
  
  # # 测试任务 - 使用最快的模型
  # dashscope_test:
  #   provider: dashscope
  #   model_name: qwen-turbo
  #   api_key_env: DASHSCOPE_API_KEY
    
  #   generation:
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 40
  #     max_output_tokens: 2000
    
  #   rate_limit:
  #     interval: 0.5
  #     max_retries: 2
  #     retry_backoff_base: 2.0
