"""
ä¼˜åŒ–çš„ Gemini TTS å®ç°
ä½¿ç”¨çœŸæ­£çš„æµå¼ API å’Œå¹¶å‘å¤„ç†æ¥å¤§å¹…æå‡æ€§èƒ½
"""

import asyncio
import logging
import base64
import re
from typing import AsyncGenerator, List, Tuple
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

# Gemini TTS æ”¯æŒçš„éŸ³è‰²åˆ—è¡¨
VALID_VOICES = {
    'achernar', 'achird', 'algenib', 'algieba', 'alnilam', 'aoede', 'autonoe',
    'callirrhoe', 'charon', 'despina', 'enceladus', 'erinome', 'fenrir',
    'gacrux', 'iapetus', 'kore', 'laomedeia', 'leda', 'orus', 'puck',
    'pulcherrima', 'rasalgethi', 'sadachbia', 'sadaltager', 'schedar',
    'sulafat', 'umbriel', 'vindemiatrix', 'zephyr', 'zubenelgenubi'
}

DEFAULT_VOICE = 'kore'


class OptimizedGeminiTTS:
    """ä¼˜åŒ–çš„ Gemini TTS å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash-exp-audio"):
        """
        åˆå§‹åŒ– TTS å®¢æˆ·ç«¯
        
        Args:
            api_key: Gemini API å¯†é’¥
            model: æ¨¡å‹åç§°ï¼ˆå¿…é¡»æ˜¯æ”¯æŒ TTS çš„æ¨¡å‹ï¼Œå¦‚ gemini-2.0-flash-exp-audioï¼‰
        """
        self.api_key = api_key
        self.model = model
        self._executor = ThreadPoolExecutor(max_workers=4)
        
        # å¯¼å…¥ SDK
        try:
            from google import genai
            from google.genai import types
            self.genai = genai
            self.types = types
            logger.info("âœ… google-genai SDK å·²åŠ è½½")
        except ImportError:
            raise ImportError(
                "éœ€è¦å®‰è£… google-genai SDK: pip install google-genai"
            )
    
    def validate_voice(self, voice: str) -> str:
        """éªŒè¯å¹¶è§„èŒƒåŒ–éŸ³è‰²"""
        if not voice:
            return DEFAULT_VOICE
        voice_lower = voice.lower()
        if voice_lower not in VALID_VOICES:
            logger.warning(f"ä¸æ”¯æŒçš„éŸ³è‰² '{voice}'ï¼Œä½¿ç”¨é»˜è®¤: {DEFAULT_VOICE}")
            return DEFAULT_VOICE
        return voice_lower
    
    def smart_chunk_text(self, text: str, max_chars: int = 800) -> List[str]:
        """
        æ™ºèƒ½åˆ†å—ï¼šæŒ‰å¥å­è¾¹ç•Œåˆ†å‰²ï¼Œé¿å…æˆªæ–­
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            max_chars: æ¯å—æœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        if len(text) <= max_chars:
            return [text]
        
        # å¥å­åˆ†éš”ç¬¦ï¼ˆä¸­è‹±æ–‡ï¼‰
        sentence_pattern = r'([ã€‚ï¼ï¼Ÿ\.!?]+)'
        parts = re.split(sentence_pattern, text)
        
        # é‡æ–°ç»„åˆå¥å­å’Œæ ‡ç‚¹
        sentences = []
        for i in range(0, len(parts), 2):
            sentence = parts[i]
            punct = parts[i + 1] if i + 1 < len(parts) else ''
            if sentence.strip():
                sentences.append(sentence + punct)
        
        # ç»„åˆæˆå—
        chunks = []
        current = ""
        
        for sentence in sentences:
            # å•å¥è¶…é•¿ï¼Œå¼ºåˆ¶åˆ†å‰²
            if len(sentence) > max_chars:
                if current:
                    chunks.append(current.strip())
                    current = ""
                # æŒ‰å­—ç¬¦å¼ºåˆ¶åˆ†å‰²
                for i in range(0, len(sentence), max_chars):
                    chunks.append(sentence[i:i + max_chars])
            # æ·»åŠ åä¼šè¶…é•¿
            elif len(current) + len(sentence) > max_chars:
                if current:
                    chunks.append(current.strip())
                current = sentence
            # æ­£å¸¸æ·»åŠ 
            else:
                current += sentence
        
        if current:
            chunks.append(current.strip())
        
        logger.info(f"ğŸ“ æ–‡æœ¬åˆ†å—: {len(text)} å­—ç¬¦ â†’ {len(chunks)} å—")
        return chunks
    
    async def stream_tts_chunk(
        self,
        text: str,
        voice: str = "kore",
        chunk_index: int = 0
    ) -> AsyncGenerator[Tuple[int, bytes], None]:
        """
        æµå¼ç”Ÿæˆå•ä¸ªæ–‡æœ¬å—çš„éŸ³é¢‘ï¼ˆä½¿ç”¨çœŸæ­£çš„æµå¼ APIï¼‰
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            voice: éŸ³è‰²
            chunk_index: å—ç´¢å¼•ï¼ˆç”¨äºæ’åºï¼‰
            
        Yields:
            (chunk_index, audio_data): å—ç´¢å¼•å’ŒéŸ³é¢‘æ•°æ®
        """
        voice = self.validate_voice(voice)
        
        logger.info(f"ğŸµ å¼€å§‹æµå¼ç”Ÿæˆå— {chunk_index}: {len(text)} å­—ç¬¦")
        
        try:
            loop = asyncio.get_event_loop()
            
            def _stream_call():
                """åŒæ­¥è°ƒç”¨æµå¼ API"""
                client = self.genai.Client(api_key=self.api_key)
                
                # ä½¿ç”¨æµå¼ API
                response_stream = client.models.generate_content_stream(
                    model=self.model,
                    contents=text,
                    config=self.types.GenerateContentConfig(
                        response_modalities=["AUDIO"],
                        speech_config=self.types.SpeechConfig(
                            voice_config=self.types.VoiceConfig(
                                prebuilt_voice_config=self.types.PrebuiltVoiceConfig(
                                    voice_name=voice
                                )
                            )
                        )
                    )
                )
                
                # æ”¶é›†æ‰€æœ‰æµå¼å—
                audio_chunks = []
                for chunk in response_stream:
                    if chunk.candidates:
                        for part in chunk.candidates[0].content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                audio_chunks.append(part.inline_data.data)
                
                return audio_chunks
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
            audio_chunks = await loop.run_in_executor(self._executor, _stream_call)
            
            # é€å—è¿”å›
            for audio_data in audio_chunks:
                if isinstance(audio_data, str):
                    pcm_data = base64.b64decode(audio_data)
                else:
                    pcm_data = audio_data
                
                # ç¼–ç ä¸º Base64 è¿”å›
                b64_data = base64.b64encode(pcm_data).decode('utf-8')
                yield (chunk_index, b64_data.encode('utf-8'))
            
            logger.info(f"âœ… å— {chunk_index} å®Œæˆ: {len(audio_chunks)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
            
        except Exception as e:
            logger.error(f"âŒ å— {chunk_index} ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def stream_tts_optimized(
        self,
        text: str,
        voice: str = "kore",
        max_chunk_size: int = 800,
        max_concurrent: int = 3
    ) -> AsyncGenerator[bytes, None]:
        """
        ä¼˜åŒ–çš„æµå¼ TTSï¼šåˆ†å— + å¹¶å‘ + æµå¼
        
        ç­–ç•¥ï¼š
        1. å°†é•¿æ–‡æœ¬æ™ºèƒ½åˆ†å—ï¼ˆæŒ‰å¥å­è¾¹ç•Œï¼‰
        2. å¹¶å‘è¯·æ±‚å¤šä¸ªå—ï¼ˆæ§åˆ¶å¹¶å‘æ•°ï¼‰
        3. æŒ‰é¡ºåºè¿”å›éŸ³é¢‘æ•°æ®
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            voice: éŸ³è‰²
            max_chunk_size: æ¯å—æœ€å¤§å­—ç¬¦æ•°
            max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
            
        Yields:
            bytes: Base64 ç¼–ç çš„éŸ³é¢‘æ•°æ®
        """
        voice = self.validate_voice(voice)
        
        # åˆ†å—
        chunks = self.smart_chunk_text(text, max_chunk_size)
        
        if len(chunks) == 1:
            # å•å—ï¼Œç›´æ¥æµå¼å¤„ç†
            logger.info("ğŸ“¦ å•å—å¤„ç†ï¼Œä½¿ç”¨æµå¼ API")
            async for _, audio_data in self.stream_tts_chunk(chunks[0], voice, 0):
                yield audio_data
            return
        
        # å¤šå—ï¼Œå¹¶å‘å¤„ç†
        logger.info(f"ğŸ“¦ å¤šå—å¤„ç†: {len(chunks)} å—ï¼Œå¹¶å‘æ•°: {max_concurrent}")
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        semaphore = asyncio.Semaphore(max_concurrent)
        results = {}  # {chunk_index: [audio_data, ...]}
        
        async def process_chunk(idx: int, chunk_text: str):
            """å¤„ç†å•ä¸ªå—"""
            async with semaphore:
                results[idx] = []
                async for _, audio_data in self.stream_tts_chunk(chunk_text, voice, idx):
                    results[idx].append(audio_data)
        
        # å¯åŠ¨æ‰€æœ‰ä»»åŠ¡
        tasks = [
            asyncio.create_task(process_chunk(i, chunk))
            for i, chunk in enumerate(chunks)
        ]
        
        # æŒ‰é¡ºåºè¿”å›ç»“æœ
        for i in range(len(chunks)):
            # ç­‰å¾…å½“å‰å—å®Œæˆ
            await tasks[i]
            
            # è¿”å›å½“å‰å—çš„æ‰€æœ‰éŸ³é¢‘æ•°æ®
            if i in results:
                for audio_data in results[i]:
                    yield audio_data
                # é‡Šæ”¾å†…å­˜
                del results[i]
        
        logger.info("ğŸ‰ æ‰€æœ‰å—å¤„ç†å®Œæˆ")
    
    async def generate_wav_file(
        self,
        text: str,
        output_path: str,
        voice: str = "kore"
    ) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„ WAV æ–‡ä»¶
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            voice: éŸ³è‰²
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import wave
        
        voice = self.validate_voice(voice)
        logger.info(f"ğŸ’¾ ç”Ÿæˆ WAV æ–‡ä»¶: {output_path}")
        
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
        pcm_chunks = []
        async for b64_data in self.stream_tts_optimized(text, voice):
            pcm_data = base64.b64decode(b64_data)
            pcm_chunks.append(pcm_data)
        
        # åˆå¹¶æ‰€æœ‰ PCM æ•°æ®
        full_pcm = b''.join(pcm_chunks)
        
        # å†™å…¥ WAV æ–‡ä»¶
        with wave.open(output_path, 'wb') as wf:
            wf.setnchannels(1)      # å•å£°é“
            wf.setsampwidth(2)      # 16-bit
            wf.setframerate(24000)  # 24kHz
            wf.writeframes(full_pcm)
        
        logger.info(f"âœ… WAV æ–‡ä»¶å·²ä¿å­˜: {output_path} ({len(full_pcm)} bytes)")
        return output_path
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, '_executor'):
            self._executor.shutdown(wait=False)


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

async def example_streaming():
    """ç¤ºä¾‹ï¼šæµå¼æ’­æ”¾"""
    import os
    
    api_key = os.getenv("GEMINI_API_KEY")
    tts = OptimizedGeminiTTS(api_key)
    
    text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚" * 100  # é•¿æ–‡æœ¬
    
    print("ğŸµ å¼€å§‹æµå¼ç”Ÿæˆ...")
    chunk_count = 0
    async for audio_chunk in tts.stream_tts_optimized(text, voice="kore"):
        chunk_count += 1
        print(f"ğŸ“¦ æ”¶åˆ°éŸ³é¢‘å— {chunk_count}: {len(audio_chunk)} bytes")
    
    print(f"âœ… å®Œæˆï¼å…± {chunk_count} ä¸ªéŸ³é¢‘å—")


async def example_save_file():
    """ç¤ºä¾‹ï¼šä¿å­˜ WAV æ–‡ä»¶"""
    import os
    
    api_key = os.getenv("GEMINI_API_KEY")
    tts = OptimizedGeminiTTS(api_key)
    
    text = "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ã€‚" * 50
    
    output_file = await tts.generate_wav_file(
        text=text,
        output_path="output_optimized.wav",
        voice="kore"
    )
    
    print(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    # æµ‹è¯•æµå¼
    asyncio.run(example_streaming())
    
    # æµ‹è¯•ä¿å­˜æ–‡ä»¶
    # asyncio.run(example_save_file())
