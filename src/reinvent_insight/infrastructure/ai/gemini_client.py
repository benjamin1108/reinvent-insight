"""Geminiæ¨¡å‹å®¢æˆ·ç«¯å®ç°"""

import asyncio
import logging
from typing import Dict, Any, Optional

from .config_models import ModelConfig, ConfigurationError, APIError
from .base_client import BaseModelClient

logger = logging.getLogger(__name__)


class GeminiClient(BaseModelClient):
    """Geminiæ¨¡å‹å®¢æˆ·ç«¯"""
    
    def __init__(self, config: ModelConfig):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            config: æ¨¡å‹é…ç½®
            
        Raises:
            ConfigurationError: API Keyæœªé…ç½®
        """
        super().__init__(config)
        
        if not config.api_key:
            raise ConfigurationError("Gemini API Key æœªé…ç½®")
        
        try:
            from google import genai
            from google.genai import types
            
            self.genai = genai
            self.types = types
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = genai.Client(api_key=config.api_key)
            
            logger.info(f"Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {config.model_name}")
            
        except ImportError:
            raise ConfigurationError("google-genai åŒ…æœªå®‰è£…")
        except Exception as e:
            raise ConfigurationError(f"Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    async def generate_content(
        self, 
        prompt: str, 
        is_json: bool = False,
        thinking_level: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬å†…å®¹
        
        Args:
            prompt: æç¤ºè¯
            is_json: æ˜¯å¦è¿”å›JSONæ ¼å¼
            thinking_level: æ€è€ƒçº§åˆ« ("low", "medium", "high")ï¼Œå¦‚æœä¸ºNoneåˆ™æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
            
        Raises:
            APIError: APIè°ƒç”¨å¤±è´¥
        """
        await self._apply_rate_limit()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šthinking_levelï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©
        if thinking_level is None:
            thinking_level = "low" if self.config.low_thinking else "high"
        
        logger.info(f"å¼€å§‹ä½¿ç”¨ {self.config.model_name} ç”Ÿæˆå†…å®¹ (thinking_level={thinking_level}, from_config={thinking_level is None})...")
        
        # ä½¿ç”¨æ–°çš„google.genai SDK
        config = self.types.GenerateContentConfig(
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            top_k=self.config.top_k,
            max_output_tokens=self.config.max_output_tokens,
            response_mime_type="application/json" if is_json else "text/plain",
            thinking_config=self.types.ThinkingConfig(thinking_level=thinking_level)
        )
        
        async def _generate():
            # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼šä½¿ç”¨é…ç½®ä¸­çš„timeoutï¼Œå¦‚æœæ˜¯é«˜æ€è€ƒæ¨¡å¼ä¸”é…ç½®è¶…æ—¶è¾ƒçŸ­ï¼Œåˆ™è‡ªåŠ¨å¢åŠ 
            # é«˜æ€è€ƒæ¨¡å¼éœ€è¦æ›´é•¿çš„æ€è€ƒæ—¶é—´
            base_timeout = self.config.timeout
            if thinking_level == "high" and base_timeout < 300:
                timeout_seconds = max(base_timeout * 1.5, 300)  # é«˜æ€è€ƒæ¨¡å¼è‡³å°‘300ç§’
                logger.debug(f"é«˜æ€è€ƒæ¨¡å¼ï¼Œè¶…æ—¶æ—¶é—´ä» {base_timeout}ç§’ å¢åŠ åˆ° {timeout_seconds}ç§’")
            else:
                timeout_seconds = base_timeout
            
            try:
                # ä½¿ç”¨ run_in_executor é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                loop = asyncio.get_event_loop()
                
                def sync_generate():
                    # ä½¿ç”¨æ–°çš„ google.genai SDK è°ƒç”¨
                    return self.client.models.generate_content(
                        model=self.config.model_name,
                        contents=prompt,
                        config=config
                    )
                
                response = await asyncio.wait_for(
                    loop.run_in_executor(None, sync_generate),
                    timeout=timeout_seconds
                )
                
                # æå–æ–‡æœ¬å†…å®¹
                if not response.text:
                    raise APIError("API è¿”å›çš„å†…å®¹ä¸ºç©ºæ–‡æœ¬")
                
                return response.text
                
            except asyncio.TimeoutError:
                raise APIError(f"API è°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡ {timeout_seconds} ç§’ï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å‡å°‘è¾“å…¥é•¿åº¦")
        
        try:
            content = await self._retry_with_backoff(_generate)
            logger.info(f"{self.config.model_name} å†…å®¹ç”Ÿæˆå®Œæˆ")
            return content
            
        except Exception as e:
            logger.error(f"è°ƒç”¨ Gemini API æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            if "API key not valid" in str(e):
                raise ConfigurationError("Gemini API å¯†é’¥æ— æ•ˆ")
            raise APIError(f"Gemini API è°ƒç”¨å¤±è´¥: {e}") from e
    
    async def generate_content_with_file(
        self,
        prompt: str,
        file_info: Dict[str, Any],
        is_json: bool = False,
        thinking_level: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨æ–‡ä»¶ç”Ÿæˆå†…å®¹ï¼ˆå¤šæ¨¡æ€ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            file_info: æ–‡ä»¶ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«nameã€uriã€local_fileç­‰å­—æ®µ
            is_json: æ˜¯å¦è¿”å›JSONæ ¼å¼
            thinking_level: æ€è€ƒçº§åˆ« ("low", "medium", "high")ï¼Œå¦‚æœä¸ºNoneåˆ™æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
            
        Raises:
            APIError: APIè°ƒç”¨å¤±è´¥
        """
        await self._apply_rate_limit()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šthinking_levelï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©
        if thinking_level is None:
            thinking_level = "low" if self.config.low_thinking else "high"
        
        logger.info(f"å¼€å§‹ä½¿ç”¨ {self.config.model_name} è¿›è¡Œå¤šæ¨¡æ€åˆ†æ (thinking_level={thinking_level})...")
        
        generation_config = self.types.GenerateContentConfig(
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            top_k=self.config.top_k,
            max_output_tokens=self.config.max_output_tokens,
            response_mime_type="application/json" if is_json else "text/plain",
            thinking_config=self.types.ThinkingConfig(thinking_level=thinking_level)
        )
        
        async def _generate():
            # æ ¹æ®æ€è€ƒçº§åˆ«è®¾ç½®è¶…æ—¶
            base_timeout = self.config.timeout
            if thinking_level == "high" and base_timeout < 300:
                timeout_seconds = max(base_timeout * 1.5, 300)
                logger.debug(f"é«˜æ€è€ƒæ¨¡å¼ï¼Œè¶…æ—¶æ—¶é—´ä» {base_timeout}ç§’ å¢åŠ åˆ° {timeout_seconds}ç§’")
            else:
                timeout_seconds = base_timeout
            
            try:
                loop = asyncio.get_event_loop()
                
                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                if file_info.get("local_file", False):
                    # ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                    file_path = file_info["uri"]
                    mime_type = file_info.get("mime_type", "application/pdf")
                    
                    def read_and_process():
                        with open(file_path, "rb") as f:
                            file_data = f.read()
                        
                        # ä½¿ç”¨æ–° SDK è°ƒç”¨
                        return self.client.models.generate_content(
                            model=self.config.model_name,
                            contents=[
                                prompt,
                                self.types.Part.from_bytes(data=file_data, mime_type=mime_type)
                            ],
                            config=generation_config
                        )
                    
                    response = await asyncio.wait_for(
                        loop.run_in_executor(None, read_and_process),
                        timeout=timeout_seconds
                    )
                else:
                    # ä½¿ç”¨å·²ä¸Šä¼ çš„æ–‡ä»¶å¼•ç”¨
                    def sync_generate_with_file():
                        file_ref = self.client.files.get(name=file_info["name"])
                        return self.client.models.generate_content(
                            model=self.config.model_name,
                            contents=[prompt, file_ref],
                            config=generation_config
                        )
                    
                    response = await asyncio.wait_for(
                        loop.run_in_executor(None, sync_generate_with_file),
                        timeout=timeout_seconds
                    )
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰å†…å®¹
                if not response.candidates:
                    raise APIError("API è¿”å›äº†ç©ºçš„å€™é€‰å†…å®¹")
                
                # æå–æ–‡æœ¬å†…å®¹
                content = ''.join(
                    part.text for part in response.candidates[0].content.parts
                )
                
                if not content:
                    raise APIError("API è¿”å›çš„å†…å®¹ä¸ºç©ºæ–‡æœ¬")
                
                return content
                
            except asyncio.TimeoutError:
                raise APIError(f"API è°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡ {timeout_seconds} ç§’ï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å‡å°‘è¾“å…¥é•¿åº¦")
        
        try:
            content = await self._retry_with_backoff(_generate)
            logger.info(f"{self.config.model_name} å¤šæ¨¡æ€åˆ†æå®Œæˆ")
            return content
            
        except Exception as e:
            logger.error(f"è°ƒç”¨ Gemini API è¿›è¡Œå¤šæ¨¡æ€åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            if "API key not valid" in str(e):
                raise ConfigurationError("Gemini API å¯†é’¥æ— æ•ˆ")
            raise APIError(f"Gemini API å¤šæ¨¡æ€è°ƒç”¨å¤±è´¥: {e}") from e
    
    async def upload_file(self, file_path: str) -> Dict[str, Any]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°Gemini API
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶ä¿¡æ¯å­—å…¸
            
        Raises:
            APIError: ä¸Šä¼ å¤±è´¥
        """
        try:
            loop = asyncio.get_event_loop()
            
            # å°è¯•ä¸Šä¼ æ–‡ä»¶
            try:
                file_obj = await loop.run_in_executor(
                    None, 
                    lambda: self.client.files.upload(file=file_path)
                )
                
                file_info = {
                    "name": file_obj.name,
                    "display_name": file_obj.display_name,
                    "mime_type": file_obj.mime_type,
                    "size_bytes": file_obj.size_bytes,
                    "create_time": file_obj.create_time,
                    "expiration_time": file_obj.expiration_time,
                    "uri": file_obj.uri,
                    "local_file": False
                }
                
                logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_info['name']}")
                return file_info
                
            except TypeError as te:
                if "ragStoreName" in str(te):
                    # APIå˜æ›´ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶å¤„ç†
                    logger.warning("æ£€æµ‹åˆ° API å˜æ›´ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶å¤„ç†")
                    
                    import os
                    file_size = os.path.getsize(file_path)
                    
                    file_info = {
                        "name": f"files/{os.path.basename(file_path)}",
                        "display_name": os.path.basename(file_path),
                        "mime_type": "application/pdf",
                        "size_bytes": file_size,
                        "create_time": None,
                        "expiration_time": None,
                        "uri": file_path,
                        "local_file": True
                    }
                    
                    logger.info(f"ä½¿ç”¨æœ¬åœ°æ–‡ä»¶å¤„ç†: {file_info['name']}")
                    return file_info
                else:
                    raise te
                    
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
            raise APIError(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}") from e
    
    async def delete_file(self, file_id: str) -> bool:
        """
        åˆ é™¤Geminiä¸Šä¼ çš„æ–‡ä»¶
        
        Args:
            file_id: æ–‡ä»¶ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None, 
                lambda: self.client.files.delete(name=file_id)
            )
            logger.info(f"å·²åˆ é™¤æ–‡ä»¶: {file_id}")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _split_text_for_streaming(self, text: str, max_chunk_size: int = 100) -> list:
        """
        å°†é•¿æ–‡æœ¬æŒ‰å¥å­åˆ‡åˆ†ä¸ºå¤šä¸ªè¾ƒçŸ­çš„ç‰‡æ®µï¼Œç”¨äºæ¨¡æ‹Ÿæµå¼ä½“éªŒ
        
        ç­–ç•¥ï¼šæŒ‰å¥å­è¾¹ç•Œï¼ˆã€‚ï¼ï¼Ÿ.!? æˆ–æ¢è¡Œç¬¦ï¼‰åˆ‡åˆ†ï¼Œæ¯ä¸ªç‰‡æ®µçº¦ 50-100 å­—
        
        Args:
            text: è¦åˆ‡åˆ†çš„æ–‡æœ¬
            max_chunk_size: æ¯ä¸ªç‰‡æ®µçš„æœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
        """
        import re
        
        # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(text) <= max_chunk_size:
            return [text]
        
        # æŒ‰å¥å­è¾¹ç•Œåˆ‡åˆ†ï¼ˆä¸­è‹±æ–‡æ ‡ç‚¹ï¼‰
        # åŒ¹é…å¥å­ç»“æŸç¬¦å·ï¼šã€‚ï¼ï¼Ÿ.!? åé¢å¯èƒ½è·Ÿå¼•å·ã€æ‹¬å·ç­‰
        sentence_pattern = r'[ã€‚ï¼ï¼Ÿ.!?]+[ã€ã€"\'ï¼‰\)]*'
        
        chunks = []
        current_chunk = ""
        
        # å…ˆæŒ‰å¥å­åˆ‡åˆ†
        sentences = re.split(f'({sentence_pattern})', text)
        
        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            # å¦‚æœæœ‰æ ‡ç‚¹ç¬¦å·ï¼ŒåŠ ä¸Š
            if i + 1 < len(sentences):
                sentence += sentences[i + 1]
            
            # å¦‚æœå½“å‰å—åŠ ä¸Šè¿™ä¸ªå¥å­ä¸è¶…è¿‡é™åˆ¶ï¼Œå°±åŠ å…¥
            if len(current_chunk) + len(sentence) <= max_chunk_size:
                current_chunk += sentence
            else:
                # å¦åˆ™ï¼Œä¿å­˜å½“å‰å—ï¼Œå¼€å§‹æ–°å—
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # å¦‚æœæ²¡æœ‰åˆ‡åˆ†æˆåŠŸï¼ˆå¯èƒ½æ²¡æœ‰å¥å­è¾¹ç•Œï¼‰ï¼Œå¼ºåˆ¶æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
        if not chunks or (len(chunks) == 1 and len(chunks[0]) > max_chunk_size):
            logger.debug("æ²¡æœ‰æ‰¾åˆ°å¥å­è¾¹ç•Œï¼Œå¼ºåˆ¶æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†")
            chunks = [text[i:i+max_chunk_size] for i in range(0, len(text), max_chunk_size)]
        
        # è¿‡æ»¤æ‰ç©ºç‰‡æ®µ
        chunks = [chunk for chunk in chunks if chunk.strip()]
        
        logger.info(f"ğŸ“„ æ–‡æœ¬åˆ‡åˆ†: {len(text)} å­—ç¬¦ â†’ {len(chunks)} ä¸ªç‰‡æ®µ")
        for i, chunk in enumerate(chunks):
            logger.debug(f"   ç‰‡æ®µ {i+1}: {len(chunk)} å­—ç¬¦")
        
        return chunks
    
    async def generate_tts_stream(
        self,
        text: str,
        voice: str = "kore",
        language: str = "zh-CN"
    ):
        """
        ç”Ÿæˆ TTS éŸ³é¢‘ï¼ˆä½¿ç”¨è¾“å…¥ç«¯åˆ†ç‰‡ç­–ç•¥å®ç°ä½å»¶è¿Ÿæµå¼æ’­æ”¾ï¼‰
        
        ç­–ç•¥ï¼š
        1. å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºå¤šä¸ªçŸ­ç‰‡æ®µï¼ˆ50-100å­—ï¼‰
        2. ä¸²è¡Œè¯·æ±‚æ¯ä¸ªç‰‡æ®µçš„ TTS
        3. ä¸€æ—¦æ”¶åˆ°ç¬¬ä¸€ä¸ªç‰‡æ®µçš„éŸ³é¢‘å°±ç«‹å³ yield
        4. æŒç»­å¤„ç†åç»­ç‰‡æ®µï¼Œå®ç°è¿ç»­æ’­æ”¾
        
        è¿™æ ·å¯ä»¥å°†é¦–å­—å»¶è¿Ÿä» 15 ç§’é™ä½åˆ° 3-5 ç§’ï¼
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: éŸ³è‰²åç§°ï¼ˆ30ç§å¯é€‰ï¼Œå¦‚ kore, puck, aoede ç­‰ï¼Œå…¨å°å†™ï¼‰
            language: è¯­è¨€ä»£ç ï¼ˆå¦‚ zh-CN, en-US ç­‰ï¼ŒGemini ä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰
            
        Yields:
            bytes: Base64 ç¼–ç çš„ PCM éŸ³é¢‘æ•°æ®
            
        Raises:
            APIError: API è°ƒç”¨å¤±è´¥
        """
        await self._apply_rate_limit()
        
        try:
            # ä½¿ç”¨æ–°çš„ google-genai SDK
            try:
                from google import genai
                from google.genai import types
                import base64
            except ImportError:
                logger.warning("google-genai SDK æœªå®‰è£…ï¼ŒTTS åŠŸèƒ½ä¸å¯ç”¨")
                raise ConfigurationError(
                    "Gemini TTS éœ€è¦ google-genai SDKã€‚è¯·å®‰è£…: pip install google-genai"
                )
            
            # è®°å½•æµå¼€å§‹çš„è¯¦ç»†ä¿¡æ¯
            start_time = asyncio.get_event_loop().time()
            logger.info(
                f"ğŸ¤ å¼€å§‹è¾“å…¥ç«¯åˆ†ç‰‡æµå¼ TTS: "
                f"model={self.config.model_name}, "
                f"voice={voice}, "
                f"language={language}, "
                f"text_length={len(text)}"
            )
            
            # ğŸ”¥ å…³é”®ç­–ç•¥ï¼šå°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºå¤šä¸ªçŸ­ç‰‡æ®µï¼ˆ20-30å­—ï¼Œçº¦2-4ç§’éŸ³é¢‘ï¼‰
            text_chunks = self._split_text_for_streaming(text, max_chunk_size=30)
            logger.info(f"âœ‚ï¸  æ–‡æœ¬å·²åˆ‡åˆ†ä¸º {len(text_chunks)} ä¸ªç‰‡æ®µ")
            
            # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­ï¼Œé¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜ï¼‰
            try:
                client = genai.Client(api_key=self.config.api_key)
                logger.debug("Gemini å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                logger.error(f"åˆ›å»º Gemini å®¢æˆ·ç«¯å¤±è´¥: {e}", exc_info=True)
                raise ConfigurationError(f"æ— æ³•åˆ›å»º Gemini å®¢æˆ·ç«¯: {e}") from e
            
            # å¤„ç†æ¯ä¸ªæ–‡æœ¬ç‰‡æ®µ
            total_chunk_count = 0
            total_bytes = 0
            first_audio_time = None
            
            for segment_index, text_segment in enumerate(text_chunks, 1):
                segment_start_time = asyncio.get_event_loop().time()
                logger.info(f"ğŸ¯ å¤„ç†ç‰‡æ®µ {segment_index}/{len(text_chunks)}: {len(text_segment)} å­—ç¬¦")
                
                # ä¸ºæ¯ä¸ªç‰‡æ®µç”ŸæˆéŸ³é¢‘
                async def generate_segment_audio(segment_text):
                    """ä¸ºå•ä¸ªæ–‡æœ¬ç‰‡æ®µç”ŸæˆéŸ³é¢‘"""
                    def _get_stream():
                        return client.models.generate_content_stream(
                            model=self.config.model_name,
                            contents=segment_text,
                            config=types.GenerateContentConfig(
                                response_modalities=["AUDIO"],
                                speech_config=types.SpeechConfig(
                                    voice_config=types.VoiceConfig(
                                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                            voice_name=voice
                                        )
                                    )
                                )
                            )
                        )
                    
                    # åœ¨çº¿ç¨‹æ± ä¸­è·å–æµ
                    stream = await asyncio.to_thread(_get_stream)
                    
                    # æ”¶é›†è¿™ä¸ªç‰‡æ®µçš„æ‰€æœ‰éŸ³é¢‘å—
                    segment_audio_chunks = []
                    chunk_index = 0
                    
                    while True:
                        try:
                            chunk = await asyncio.to_thread(lambda: next(stream, None))
                            if chunk is None:
                                break
                            
                            chunk_index += 1
                            
                            # è§£æéŸ³é¢‘æ•°æ®
                            if hasattr(chunk, 'candidates') and chunk.candidates:
                                candidate = chunk.candidates[0]
                                if hasattr(candidate, 'content') and candidate.content:
                                    if hasattr(candidate.content, 'parts') and candidate.content.parts:
                                        for part in candidate.content.parts:
                                            if hasattr(part, 'inline_data') and part.inline_data:
                                                if hasattr(part.inline_data, 'data') and part.inline_data.data:
                                                    audio_data = part.inline_data.data
                                                    
                                                    # è§£ç éŸ³é¢‘æ•°æ®
                                                    if isinstance(audio_data, str):
                                                        pcm_data = base64.b64decode(audio_data)
                                                    else:
                                                        pcm_data = audio_data
                                                    
                                                    if pcm_data:
                                                        segment_audio_chunks.append(pcm_data)
                        
                        except StopIteration:
                            break
                        except Exception as e:
                            logger.error(f"è¯»å–ç‰‡æ®µéŸ³é¢‘å—æ—¶å‡ºé”™: {e}")
                            break
                    
                    return segment_audio_chunks
                
                # ç”Ÿæˆè¿™ä¸ªç‰‡æ®µçš„éŸ³é¢‘
                segment_audio_chunks = await generate_segment_audio(text_segment)
                
                if not segment_audio_chunks:
                    logger.warning(f"âš ï¸  ç‰‡æ®µ {segment_index} æ²¡æœ‰ç”ŸæˆéŸ³é¢‘ï¼Œè·³è¿‡")
                    continue
                
                # è®°å½•é¦–ä¸ªéŸ³é¢‘ç‰‡æ®µçš„å»¶è¿Ÿ
                if first_audio_time is None:
                    first_audio_time = asyncio.get_event_loop().time()
                    first_audio_latency = first_audio_time - start_time
                    logger.info(f"âš¡ é¦–ä¸ªéŸ³é¢‘ç‰‡æ®µå»¶è¿Ÿ: {first_audio_latency:.2f}s ï¼ˆç›®æ ‡ < 5sï¼‰")
                
                # ç«‹å³ yield è¿™ä¸ªç‰‡æ®µçš„æ‰€æœ‰éŸ³é¢‘å—
                for pcm_data in segment_audio_chunks:
                    b64_data = base64.b64encode(pcm_data).decode('utf-8')
                    total_chunk_count += 1
                    total_bytes += len(pcm_data)
                    
                    logger.info(
                        f"ğŸ“¦ å‘é€ç‰‡æ®µ {segment_index} çš„éŸ³é¢‘: "
                        f"{len(pcm_data)} bytes, "
                        f"ç´¯è®¡ {total_bytes / 1024:.1f}KB"
                    )
                    
                    # âœ… ç«‹å³ yield ç»™å‰ç«¯æ’­æ”¾ï¼
                    yield b64_data.encode('utf-8')
                
                segment_time = asyncio.get_event_loop().time() - segment_start_time
                logger.info(f"âœ… ç‰‡æ®µ {segment_index} å®Œæˆï¼Œè€—æ—¶ {segment_time:.2f}s")
            
            # è®°å½•å®Œæˆç»Ÿè®¡
            end_time = asyncio.get_event_loop().time()
            total_time = end_time - start_time
            
            if total_chunk_count == 0:
                logger.warning("âš ï¸  æµå¼ TTS å®Œæˆä½†æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘")
            else:
                avg_chunk_size = total_bytes / total_chunk_count if total_chunk_count > 0 else 0
                logger.info(
                    f"ğŸ‰ è¾“å…¥ç«¯åˆ†ç‰‡æµå¼ TTS å®Œæˆ: "
                    f"{len(text_chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µ, "
                    f"{total_chunk_count} ä¸ªéŸ³é¢‘å—, "
                    f"{total_bytes / 1024:.1f}KB, "
                    f"å¹³å‡å—å¤§å° {avg_chunk_size / 1024:.1f}KB, "
                    f"æ€»æ—¶é•¿ {total_time:.2f}s"
                )
                
                if first_audio_time:
                    first_audio_latency = first_audio_time - start_time
                    logger.info(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡: é¦–éŸ³é¢‘å»¶è¿Ÿ {first_audio_latency:.2f}s")
                    
                    if first_audio_latency < 5.0:
                        logger.info("ğŸ¯ æˆåŠŸï¼é¦–éŸ³é¢‘å»¶è¿Ÿ < 5 ç§’")
                    elif first_audio_latency < 10.0:
                        logger.info("âœ… è‰¯å¥½ï¼é¦–éŸ³é¢‘å»¶è¿Ÿ < 10 ç§’")
                    else:
                        logger.warning(f"âš ï¸  é¦–éŸ³é¢‘å»¶è¿Ÿè¾ƒé•¿: {first_audio_latency:.2f}s")
            
        except ConfigurationError:
            # é…ç½®é”™è¯¯ç›´æ¥æŠ›å‡º
            raise
        except Exception as e:
            # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¸Šä¸‹æ–‡
            error_context = {
                'model': self.config.model_name,
                'voice': voice,
                'language': language,
                'text_length': len(text),
                'error_type': type(e).__name__,
                'error_message': str(e)
            }
            
            logger.error(
                f"âŒ æµå¼ TTS å¤±è´¥: {e}\n"
                f"   ä¸Šä¸‹æ–‡: {error_context}",
                exc_info=True
            )
            
            # æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
            error_str = str(e).lower()
            
            if "api key not valid" in error_str or "invalid api key" in error_str:
                raise ConfigurationError(
                    f"Gemini API å¯†é’¥æ— æ•ˆã€‚è¯·æ£€æŸ¥ GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚"
                ) from e
            
            if "voice name" in error_str and "not supported" in error_str:
                raise APIError(
                    f"ä¸æ”¯æŒçš„éŸ³è‰² '{voice}'ã€‚"
                    f"è¯·ä½¿ç”¨æ”¯æŒçš„éŸ³è‰²ï¼ˆå¦‚ kore, puck, aoede ç­‰ï¼‰ã€‚"
                ) from e
            
            if "quota" in error_str or "rate limit" in error_str:
                raise APIError(
                    f"API é…é¢å·²ç”¨å°½æˆ–é€Ÿç‡é™åˆ¶ã€‚è¯·ç¨åé‡è¯•ã€‚"
                ) from e
            
            if "client has been closed" in error_str:
                raise APIError(
                    f"API å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­ã€‚è¿™å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–è¶…æ—¶ã€‚"
                ) from e
            
            # é€šç”¨é”™è¯¯
            raise APIError(
                f"Gemini TTS æµå¼ç”Ÿæˆå¤±è´¥: {e}\n"
                f"æ¨¡å‹: {self.config.model_name}, éŸ³è‰²: {voice}"
            ) from e
    
    async def generate_tts(
        self,
        text: str,
        voice: str = "Kore",
        language: str = "zh-CN"
    ) -> bytes:
        """
        ç”Ÿæˆå®Œæ•´çš„ TTS éŸ³é¢‘ï¼ˆéæµå¼ï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: éŸ³è‰²åç§°
            language: è¯­è¨€ä»£ç 
            
        Returns:
            Base64 ç¼–ç çš„ PCM éŸ³é¢‘æ•°æ®
            
        Raises:
            APIError: API è°ƒç”¨å¤±è´¥
        """
        audio_data = None
        async for chunk in self.generate_tts_stream(text, voice, language):
            audio_data = chunk
            break  # Gemini TTS è¿”å›å®Œæ•´éŸ³é¢‘ï¼Œåªæœ‰ä¸€ä¸ªå—
        
        if not audio_data:
            raise APIError("æœªæ”¶åˆ°éŸ³é¢‘æ•°æ®")
        
        return audio_data



# ============================================================================
# DashScope (é˜¿é‡Œäº‘é€šä¹‰åƒé—®) æ¨¡å‹å®¢æˆ·ç«¯
# ============================================================================

