#!/usr/bin/env python3
"""
æ‰‹åŠ¨æµ‹è¯•è¾“å…¥ç«¯åˆ†ç‰‡ç­–ç•¥çš„å®é™…æ•ˆæœ

è¿è¡Œæ–¹å¼:
    export GEMINI_API_KEY=your_key
    python tests/manual_test_chunking.py
"""
import asyncio
import os
import sys
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.reinvent_insight.model_config import GeminiClient, ModelConfig


async def test_short_chunks():
    """æµ‹è¯•çŸ­ç‰‡æ®µç­–ç•¥"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: éœ€è¦è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    config = ModelConfig(
        task_type="text_to_speech",
        provider="gemini",
        model_name="gemini-2.5-flash-preview-tts",
        api_key=api_key,
        temperature=0.7,
        top_p=0.9,
        top_k=40,
        max_output_tokens=8000
    )
    client = GeminiClient(config)
    
    # ä½¿ç”¨å¤šä¸ªçŸ­å¥å­æµ‹è¯•ï¼ˆç¡®ä¿ä¼šè¢«åˆ‡åˆ†ï¼‰
    text = """ä½ å¥½ï¼Œè¿™æ˜¯ç¬¬ä¸€å¥è¯ã€‚è¿™æ˜¯ç¬¬äºŒå¥è¯ã€‚è¿™æ˜¯ç¬¬ä¸‰å¥è¯ã€‚
    è¿™æ˜¯ç¬¬å››å¥è¯ã€‚è¿™æ˜¯ç¬¬äº”å¥è¯ã€‚è¿™æ˜¯ç¬¬å…­å¥è¯ã€‚
    è¿™æ˜¯ç¬¬ä¸ƒå¥è¯ã€‚è¿™æ˜¯ç¬¬å…«å¥è¯ã€‚è¿™æ˜¯ç¬¬ä¹å¥è¯ã€‚
    è¿™æ˜¯ç¬¬åå¥è¯ã€‚è¿™æ˜¯ç¬¬åä¸€å¥è¯ã€‚è¿™æ˜¯ç¬¬åäºŒå¥è¯ã€‚"""
    
    print("=" * 70)
    print("ğŸ¬ æµ‹è¯•è¾“å…¥ç«¯åˆ†ç‰‡ç­–ç•¥ï¼ˆçŸ­ç‰‡æ®µï¼‰")
    print("=" * 70)
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {text}")
    print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    print()
    
    # å…ˆçœ‹çœ‹ä¼šåˆ‡åˆ†æˆå‡ ä¸ªç‰‡æ®µ
    chunks = client._split_text_for_streaming(text, max_chunk_size=50)
    print(f"âœ‚ï¸  æ–‡æœ¬å°†è¢«åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µ:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   ç‰‡æ®µ {i}: {len(chunk)} å­— - {chunk}")
    print()
    
    start_time = time.time()
    first_chunk_time = None
    chunk_count = 0
    total_bytes = 0
    
    print("ğŸµ å¼€å§‹ç”ŸæˆéŸ³é¢‘...")
    print()
    
    try:
        async for audio_chunk in client.generate_tts_stream(text, "kore", "zh-CN"):
            current_time = time.time()
            
            if first_chunk_time is None:
                first_chunk_time = current_time
                latency = first_chunk_time - start_time
                print(f"âš¡ é¦–å—å»¶è¿Ÿ: {latency:.2f}s")
                
                if latency < 5.0:
                    print("ğŸ¯ æˆåŠŸï¼å»¶è¿Ÿ < 5 ç§’")
                elif latency < 8.0:
                    print("âœ… è‰¯å¥½ï¼å»¶è¿Ÿ < 8 ç§’")
                else:
                    print(f"âš ï¸  å»¶è¿Ÿè¾ƒé•¿: {latency:.2f}s")
                print()
            
            chunk_count += 1
            chunk_size = len(audio_chunk)
            total_bytes += chunk_size
            elapsed = current_time - start_time
            
            print(f"ğŸ“¦ éŸ³é¢‘å— {chunk_count}: {chunk_size} bytes, ç´¯è®¡ {total_bytes/1024:.1f}KB, {elapsed:.2f}s")
        
        total_time = time.time() - start_time
        print()
        print("=" * 70)
        print("âœ… æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        print(f"ğŸ“Š ç»Ÿè®¡:")
        print(f"   æ–‡æœ¬ç‰‡æ®µæ•°: {len(chunks)}")
        print(f"   éŸ³é¢‘å—æ•°: {chunk_count}")
        print(f"   æ€»å¤§å°: {total_bytes/1024:.1f}KB")
        print(f"   æ€»æ—¶é•¿: {total_time:.2f}s")
        print(f"   é¦–å—å»¶è¿Ÿ: {first_chunk_time - start_time:.2f}s" if first_chunk_time else "   N/A")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_short_chunks())
